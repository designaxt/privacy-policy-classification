{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "unable to import 'smart_open.gcs', disabling that module\n"
     ]
    }
   ],
   "source": [
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import sklearn\n",
    "import pandas as pd\n",
    "import os\n",
    "import time\n",
    "import tensorflow as tf\n",
    "import tensorflow_core as tfc\n",
    "import csv\n",
    "import json\n",
    "import re\n",
    "import sys\n",
    "import count_data as cd\n",
    "import load_data as ld\n",
    "import gensim\n",
    "import nltk\n",
    "\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import backend as K\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "from tensorflow_core.python.keras.callbacks import LearningRateScheduler\n",
    "from nltk.tokenize import WordPunctTokenizer\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from nltk import word_tokenize\n",
    "from gensim import corpora\n",
    "from nltk import pos_tag\n",
    "from nltk.corpus import wordnet\n",
    "from collections import defaultdict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def single_f1(y_pred, y_label, activation='softmax', threshold=0.5):\n",
    "    y_true = [[]]\n",
    "    if activation == 'softmax':  \n",
    "        for item in y_label.numpy():\n",
    "            y_true[0].append(item)\n",
    "        y_true = tf.constant(y_true)\n",
    "        y_hat = []\n",
    "        for item in y_pred:\n",
    "            if item[0] > item[1]:\n",
    "                y_hat.append([0.])\n",
    "            else:\n",
    "                y_hat.append([1.])\n",
    "        y_hat = tf.constant(y_hat)\n",
    "    if activation == 'sigmoid':\n",
    "        for item in y_label.numpy():\n",
    "            y_true[0].append(item)\n",
    "        y_true = tf.constant(y_true)\n",
    "        y_hat = []\n",
    "        for item in y_pred:\n",
    "            if item < threshold:\n",
    "                y_hat.append([0.])\n",
    "            else:\n",
    "                y_hat.append([1.])\n",
    "        y_hat = tf.constant(y_hat)\n",
    "        \n",
    "    epsilon = 1e-7\n",
    "  \n",
    "    tp = tf.cast(tf.matmul(y_true,y_hat), 'float')\n",
    "    #tn = tf.sum(tf.cast((1-y_hat)*(1-y_true), 'float'), axis=0)\n",
    "    fp = tf.cast(tf.matmul(1-y_true,y_hat), 'float')\n",
    "    fn = tf.cast(tf.matmul(y_true,1-y_hat), 'float')\n",
    "   \n",
    "    p = tp/(tp+fp+epsilon)\n",
    "    r = tp/(tp+fn+epsilon)\n",
    "    \n",
    "    f1 = 2*p*r/(p+r+epsilon)\n",
    "    \n",
    "    result = [f1[0][0].numpy(),\n",
    "              p[0][0].numpy(), \n",
    "              r[0][0].numpy(),\n",
    "              tp[0][0].numpy(),\n",
    "              fp[0][0].numpy(),\n",
    "              fn[0][0].numpy()]\n",
    "    return result"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "计算F1得分<br>对于sigmoid激活函数的输出可设置判定阈值<br>返回F1，recall，precision，tp，fp，fn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_train(max_length = 100):\n",
    "    (x_train, y_train), (x_test, y_test) = ld.load_data('data/clean_data_0.5_no_repeat.csv')\n",
    "    y_train = ld.transform_to_multi_class(y_train)\n",
    "    y_test = ld.transform_to_multi_class(y_test)\n",
    "    tokenizer = Tokenizer(oov_token='<OOV>')\n",
    "    tokenizer.fit_on_texts(x_train)\n",
    "    word_index = tokenizer.word_index\n",
    "\n",
    "    x_train = tokenizer.texts_to_sequences(x_train)\n",
    "    x_train = pad_sequences(x_train, padding='post', maxlen=max_length)\n",
    "\n",
    "    x_test = tokenizer.texts_to_sequences(x_test)\n",
    "    x_test = pad_sequences(x_test, padding='post', maxlen=max_length)\n",
    "    return (x_train, y_train), (x_test, y_test),word_index"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "生成训练测试集以及词表"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_model(model_type,model_name, embedding_dim=100):\n",
    "    if model_type == 'word2vec':\n",
    "        model = gensim.models.word2vec.Word2Vec.load(\"data/{}.w2v\".format(model_name)).wv\n",
    "    elif model_type == 'doc2vec':\n",
    "        model = gensim.models.doc2vec.Doc2Vec.load(\"data/{}.d2v\".format(model_name))\n",
    "    elif model_type == 'google':\n",
    "        model = gensim.models.KeyedVectors.load_word2vec_format(\n",
    "            '../input/GoogleNews-vectors-negative300.bin', binary=True)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "加载3种不同模型，分别为word2vec，doc2vec以及google-news预训练模型"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_embedding_matrix(model):\n",
    "    embedding_matrix = np.zeros((len(word_index) + 1, model.vector_size))\n",
    "    for word, index in word_index.items():\n",
    "        try:\n",
    "            embedding_vector = model.__getitem__(str(word))\n",
    "            embedding_matrix[int(index)] = embedding_vector\n",
    "        except KeyError:\n",
    "            continue\n",
    "    return embedding_matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "生成词向量矩阵"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def bi_LSTM_attention_model(word_index,embedding_dim,max_length, embedding_matrix,weight):\n",
    "    main_input = tf.keras.layers.Input(shape=(max_length,))\n",
    "    embedder = tf.keras.layers.Embedding(len(word_index) + 1, \n",
    "                                         embedding_dim, \n",
    "                                         input_length=max_length,\n",
    "                                         weights=[embedding_matrix],\n",
    "                                         trainable=True)\n",
    "    embed = embedder(main_input)\n",
    "    bilstm = tf.keras.layers.Bidirectional(tf.keras.layers.LSTM(128, return_sequences=True))(embed)\n",
    "    attention = tf.keras.layers.Attention()([bilstm, bilstm])\n",
    "    pooling1 = tf.keras.layers.GlobalMaxPooling1D()(bilstm)\n",
    "    pooling2 = tf.keras.layers.GlobalMaxPooling1D()(attention)\n",
    "    merge = tf.keras.layers.Concatenate()([pooling1, pooling2])\n",
    "    dense = tf.keras.layers.Dense(units=64, activation='relu')(merge)\n",
    "    main_output = tf.keras.layers.Dense(1, activation='sigmoid')(dense)\n",
    "    \n",
    "    model = tf.keras.models.Model(inputs=main_input, outputs=main_output)\n",
    "    model.compile(loss=get_weight(weight), optimizer='adam', metrics=['accuracy']) \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def TextCNN_model(word_index,embedding_dim,max_length, embedding_matrix,weight):    \n",
    "    main_input = tf.keras.layers.Input(shape=(max_length,))\n",
    "    embedder = tf.keras.layers.Embedding(len(word_index) + 1, \n",
    "                                         embedding_dim, \n",
    "                                         input_length=max_length,\n",
    "                                         weights=[embedding_matrix],\n",
    "                                         trainable=True)\n",
    "    embed = embedder(main_input)\n",
    "    cnn1 = tf.keras.layers.Conv1D(128, 3, padding='same', strides=1, activation='relu')(embed)\n",
    "    cnn1 = tf.keras.layers.GlobalMaxPooling1D()(cnn1)\n",
    "    drop = tf.keras.layers.Dropout(0.5)(cnn1)\n",
    "    dense = tf.keras.layers.Dense(units=32, activation='relu')(drop)\n",
    "    main_output = tf.keras.layers.Dense(1, activation='sigmoid')(dense)\n",
    "    \n",
    "    model = tf.keras.models.Model(inputs=main_input, outputs=main_output)\n",
    "    model.compile(loss=get_weight(weight), optimizer='adam', metrics=['accuracy']) \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_epochs =20\n",
    "learning_rate=0.0005\n",
    "def scheduler(epoch):\n",
    "    if epoch < num_epochs * 0.3:\n",
    "        return learning_rate\n",
    "    if epoch < num_epochs * 0.6:\n",
    "        return learning_rate * 0.5\n",
    "    return learning_rate * 0.1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "自定义学习率下降策略，实际没有使用"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_weight_value(y_true):\n",
    "    count = [0, 0]\n",
    "    weight = [0, 0]\n",
    "    for i in y_true.numpy():\n",
    "        if i == 0:\n",
    "            count[0] += 1\n",
    "    count[1] = len(y_true) - count[0]\n",
    "    weight[0] = count[1]/len(y_true)\n",
    "    weight[1] = count[0]/len(y_true)\n",
    "    return weight\n",
    "\n",
    "def get_weight(weight):\n",
    "    def mycrossentropy(y_true, y_pred):\n",
    "        #pt_1 = tf.ones_like(y_pred)-tf.where(tf.equal(y_true, 1), y_pred, tf.ones_like(y_pred))\n",
    "        #pt_0 = tf.where(tf.equal(y_true, 0), y_pred, tf.zeros_like(y_pred))\n",
    "        pt_1 = tf.where(tf.equal(y_true, 1), y_pred, tf.zeros_like(y_pred))\n",
    "        pt_0 = tf.where(tf.equal(y_true, 0), y_pred, tf.ones_like(y_pred))\n",
    "        loss = (1-weight)*K.binary_crossentropy(y_true, y_pred)*pt_1+(weight)*K.binary_crossentropy(y_true, y_pred)*pt_0\n",
    "        return loss\n",
    "    return mycrossentropy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "定义损失函数权重"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_model(x_train,y_train,\n",
    "              x_test,y_test, \n",
    "              word_index,\n",
    "              embedding_dim,\n",
    "              max_length, \n",
    "              embedding_matrix,\n",
    "              weight,\n",
    "              model_name='TextCNN_model',\n",
    "              if_scheduler=False):\n",
    "    callbacks = [tf.keras.callbacks.EarlyStopping(monitor='val_loss', patience=2)]\n",
    "    if if_scheduler:\n",
    "        callbacks.append(tfc.python.keras.callbacks.LearningRateScheduler(scheduler))\n",
    "    models = []\n",
    "    histories = []\n",
    "    for i in range(12):\n",
    "        if model_name == 'TextCNN_model':\n",
    "            model = TextCNN_model(word_index,embedding_dim,max_length,embedding_matrix,weight)\n",
    "        elif model_name == 'bi_LSTM_attention_model':\n",
    "            model = bi_LSTM_attention_model(word_index,embedding_dim,max_length,embedding_matrix,weight)\n",
    "        histories.append(model.fit(x_train,\n",
    "                                   y_train[i],\n",
    "                                   epochs=50,\n",
    "                                   validation_split=0.2,\n",
    "                                   callbacks=callbacks,\n",
    "                                   verbose=2))\n",
    "        model.evaluate(x_test, y_test[i], verbose=2)\n",
    "        models.append(model)\n",
    "    return (models,histories)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "训练分类器，一次性训练12个针对各类别的分类器"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def get_score(models,x_test,y_test):\n",
    "    type_dic = {'Introductory/Generic': 0, 'Practice not covered': 1,\n",
    "                'Privacy contact information': 2, 'User Access, Edit and Deletion': 3,\n",
    "                'Data Security': 4, 'International and Specific Audiences': 5,\n",
    "                'Do Not Track': 6, 'User Choice/Control': 7,\n",
    "                'Data Retention': 8, 'Policy Change': 9,\n",
    "                'First Party Collection/Use': 10, 'Third Party Sharing/Collection': 11}\n",
    "    index = 0\n",
    "    table_result = []\n",
    "    for key, value in type_dic.items():\n",
    "        result = single_f1(models[index].predict(x_test), y_test[index], 'sigmoid', 0.5)\n",
    "        index = index+1\n",
    "        table_result.append([result[0], result[1], result[2]])\n",
    "    return table_result"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "在测试集测试，获取得分"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "def save_result(result,file_name,run_num):\n",
    "    av_F = []\n",
    "    av_p = []\n",
    "    av_r = []\n",
    "    for i in range(12):\n",
    "        f = 0\n",
    "        p = 0\n",
    "        r = 0\n",
    "        for j in range(run_num):\n",
    "            f = f+result[j][i][0]\n",
    "            p = p+result[j][i][1]\n",
    "            r = r+result[j][i][2]\n",
    "        av_F.append(f/run_num)\n",
    "        av_p.append(p/run_num)\n",
    "        av_r.append(r/run_num)\n",
    "    table_result = []\n",
    "    all_F1 = 0\n",
    "    all_P = 0\n",
    "    all_R = 0\n",
    "    for i in range(12):\n",
    "        table_result.append(['/'.join([str('%.2f' % e) for e in [av_F[i],av_p[i],av_r[i]]])])\n",
    "        all_F1 = all_F1+av_F[i]\n",
    "        all_P = all_P+av_p[i]\n",
    "        all_R = all_R+av_r[i]\n",
    "    table_result.append(['/'.join([str('%.2f' % e) for e in [all_F1/12, all_P/12, all_R/12]])])\n",
    "    print(table_result)\n",
    "    with open(r'{}.csv'.format(file_name), 'w', encoding='gbk', newline='') as f:\n",
    "                writer = csv.writer(f, dialect=csv.excel, delimiter=',')\n",
    "                for data in table_result:\n",
    "                    writer.writerow(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "计算平均值，将数据导出保存"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.17559322033898306, 0.8244067796610169]\n",
      "Train on 2360 samples, validate on 590 samples\n",
      "Epoch 1/50\n",
      "2360/2360 - 2s - loss: 0.1126 - accuracy: 0.6072 - val_loss: 0.0836 - val_accuracy: 0.8271\n",
      "Epoch 2/50\n",
      "2360/2360 - 1s - loss: 0.0907 - accuracy: 0.6725 - val_loss: 0.0802 - val_accuracy: 0.7763\n",
      "Epoch 3/50\n",
      "2360/2360 - 1s - loss: 0.0847 - accuracy: 0.7055 - val_loss: 0.0787 - val_accuracy: 0.8068\n",
      "Epoch 4/50\n",
      "2360/2360 - 1s - loss: 0.0835 - accuracy: 0.7364 - val_loss: 0.0769 - val_accuracy: 0.8220\n",
      "Epoch 5/50\n",
      "2360/2360 - 1s - loss: 0.0785 - accuracy: 0.7305 - val_loss: 0.0748 - val_accuracy: 0.7780\n",
      "Epoch 6/50\n",
      "2360/2360 - 1s - loss: 0.0736 - accuracy: 0.7695 - val_loss: 0.0742 - val_accuracy: 0.7542\n",
      "Epoch 7/50\n",
      "2360/2360 - 1s - loss: 0.0699 - accuracy: 0.7928 - val_loss: 0.0775 - val_accuracy: 0.8525\n",
      "Epoch 8/50\n",
      "2360/2360 - 1s - loss: 0.0604 - accuracy: 0.8237 - val_loss: 0.0809 - val_accuracy: 0.8593\n",
      "738/1 - 0s - loss: 0.0478 - accuracy: 0.8509\n",
      "[0.1511864406779661, 0.848813559322034]\n",
      "Train on 2360 samples, validate on 590 samples\n",
      "Epoch 1/50\n",
      "2360/2360 - 2s - loss: 0.1159 - accuracy: 0.5610 - val_loss: 0.0920 - val_accuracy: 0.3898\n",
      "Epoch 2/50\n",
      "2360/2360 - 1s - loss: 0.0914 - accuracy: 0.5822 - val_loss: 0.0926 - val_accuracy: 0.7051\n",
      "Epoch 3/50\n",
      "2360/2360 - 1s - loss: 0.0855 - accuracy: 0.6436 - val_loss: 0.0866 - val_accuracy: 0.5898\n",
      "Epoch 4/50\n",
      "2360/2360 - 1s - loss: 0.0799 - accuracy: 0.6585 - val_loss: 0.0889 - val_accuracy: 0.7322\n",
      "Epoch 5/50\n",
      "2360/2360 - 1s - loss: 0.0727 - accuracy: 0.7136 - val_loss: 0.0887 - val_accuracy: 0.7678\n",
      "738/1 - 0s - loss: 0.0474 - accuracy: 0.7696\n",
      "[0.08203389830508474, 0.9179661016949152]\n",
      "Train on 2360 samples, validate on 590 samples\n",
      "Epoch 1/50\n",
      "2360/2360 - 2s - loss: 0.0636 - accuracy: 0.6453 - val_loss: 0.0355 - val_accuracy: 0.8068\n",
      "Epoch 2/50\n",
      "2360/2360 - 1s - loss: 0.0357 - accuracy: 0.7831 - val_loss: 0.0281 - val_accuracy: 0.8898\n",
      "Epoch 3/50\n",
      "2360/2360 - 1s - loss: 0.0275 - accuracy: 0.8500 - val_loss: 0.0258 - val_accuracy: 0.8576\n",
      "Epoch 4/50\n",
      "2360/2360 - 1s - loss: 0.0227 - accuracy: 0.8894 - val_loss: 0.0238 - val_accuracy: 0.8949\n",
      "Epoch 5/50\n",
      "2360/2360 - 1s - loss: 0.0185 - accuracy: 0.9059 - val_loss: 0.0252 - val_accuracy: 0.8169\n",
      "Epoch 6/50\n",
      "2360/2360 - 1s - loss: 0.0154 - accuracy: 0.9169 - val_loss: 0.0225 - val_accuracy: 0.9390\n",
      "Epoch 7/50\n",
      "2360/2360 - 1s - loss: 0.0141 - accuracy: 0.9314 - val_loss: 0.0281 - val_accuracy: 0.9424\n",
      "Epoch 8/50\n",
      "2360/2360 - 1s - loss: 0.0125 - accuracy: 0.9411 - val_loss: 0.0263 - val_accuracy: 0.9475\n",
      "738/1 - 0s - loss: 0.0115 - accuracy: 0.9485\n",
      "[0.06271186440677966, 0.9372881355932203]\n",
      "Train on 2360 samples, validate on 590 samples\n",
      "Epoch 1/50\n",
      "2360/2360 - 2s - loss: 0.0537 - accuracy: 0.6157 - val_loss: 0.0384 - val_accuracy: 0.4000\n",
      "Epoch 2/50\n",
      "2360/2360 - 1s - loss: 0.0384 - accuracy: 0.6924 - val_loss: 0.0355 - val_accuracy: 0.7068\n",
      "Epoch 3/50\n",
      "2360/2360 - 1s - loss: 0.0311 - accuracy: 0.7619 - val_loss: 0.0339 - val_accuracy: 0.6322\n",
      "Epoch 4/50\n",
      "2360/2360 - 1s - loss: 0.0275 - accuracy: 0.7792 - val_loss: 0.0397 - val_accuracy: 0.8729\n",
      "Epoch 5/50\n",
      "2360/2360 - 1s - loss: 0.0238 - accuracy: 0.8153 - val_loss: 0.0389 - val_accuracy: 0.8932\n",
      "738/1 - 0s - loss: 0.0359 - accuracy: 0.9119\n",
      "[0.09966101694915254, 0.9003389830508475]\n",
      "Train on 2360 samples, validate on 590 samples\n",
      "Epoch 1/50\n",
      "2360/2360 - 3s - loss: 0.0728 - accuracy: 0.5864 - val_loss: 0.0567 - val_accuracy: 0.2525\n",
      "Epoch 2/50\n",
      "2360/2360 - 1s - loss: 0.0511 - accuracy: 0.7127 - val_loss: 0.0456 - val_accuracy: 0.6373\n",
      "Epoch 3/50\n",
      "2360/2360 - 1s - loss: 0.0461 - accuracy: 0.7903 - val_loss: 0.0418 - val_accuracy: 0.8763\n",
      "Epoch 4/50\n",
      "2360/2360 - 1s - loss: 0.0412 - accuracy: 0.8377 - val_loss: 0.0388 - val_accuracy: 0.8085\n",
      "Epoch 5/50\n",
      "2360/2360 - 1s - loss: 0.0382 - accuracy: 0.8593 - val_loss: 0.0423 - val_accuracy: 0.6898\n",
      "Epoch 6/50\n",
      "2360/2360 - 1s - loss: 0.0328 - accuracy: 0.8784 - val_loss: 0.0379 - val_accuracy: 0.9051\n",
      "Epoch 7/50\n",
      "2360/2360 - 1s - loss: 0.0272 - accuracy: 0.8983 - val_loss: 0.0368 - val_accuracy: 0.8237\n",
      "Epoch 8/50\n",
      "2360/2360 - 1s - loss: 0.0253 - accuracy: 0.9068 - val_loss: 0.0359 - val_accuracy: 0.8831\n",
      "Epoch 9/50\n",
      "2360/2360 - 1s - loss: 0.0227 - accuracy: 0.9144 - val_loss: 0.0367 - val_accuracy: 0.9068\n",
      "Epoch 10/50\n",
      "2360/2360 - 1s - loss: 0.0202 - accuracy: 0.9242 - val_loss: 0.0391 - val_accuracy: 0.9136\n",
      "738/1 - 0s - loss: 0.0222 - accuracy: 0.9187\n",
      "[0.09627118644067796, 0.903728813559322]\n",
      "Train on 2360 samples, validate on 590 samples\n",
      "Epoch 1/50\n",
      "2360/2360 - 2s - loss: 0.0671 - accuracy: 0.6462 - val_loss: 0.0407 - val_accuracy: 0.7797\n",
      "Epoch 2/50\n",
      "2360/2360 - 1s - loss: 0.0401 - accuracy: 0.8030 - val_loss: 0.0375 - val_accuracy: 0.7729\n",
      "Epoch 3/50\n",
      "2360/2360 - 1s - loss: 0.0291 - accuracy: 0.8644 - val_loss: 0.0351 - val_accuracy: 0.7864\n",
      "Epoch 4/50\n",
      "2360/2360 - 1s - loss: 0.0227 - accuracy: 0.9072 - val_loss: 0.0322 - val_accuracy: 0.7797\n",
      "Epoch 5/50\n",
      "2360/2360 - 1s - loss: 0.0188 - accuracy: 0.9212 - val_loss: 0.0298 - val_accuracy: 0.8390\n",
      "Epoch 6/50\n",
      "2360/2360 - 1s - loss: 0.0167 - accuracy: 0.9403 - val_loss: 0.0287 - val_accuracy: 0.8322\n",
      "Epoch 7/50\n",
      "2360/2360 - 1s - loss: 0.0159 - accuracy: 0.9364 - val_loss: 0.0295 - val_accuracy: 0.8390\n",
      "Epoch 8/50\n",
      "2360/2360 - 1s - loss: 0.0128 - accuracy: 0.9513 - val_loss: 0.0318 - val_accuracy: 0.7695\n",
      "738/1 - 0s - loss: 0.0449 - accuracy: 0.8794\n",
      "[0.009152542372881356, 0.9908474576271187]\n",
      "Train on 2360 samples, validate on 590 samples\n",
      "Epoch 1/50\n",
      "2360/2360 - 2s - loss: 0.0113 - accuracy: 0.8008 - val_loss: 0.0040 - val_accuracy: 0.6136\n",
      "Epoch 2/50\n",
      "2360/2360 - 1s - loss: 0.0038 - accuracy: 0.8038 - val_loss: 0.0027 - val_accuracy: 0.7542\n",
      "Epoch 3/50\n",
      "2360/2360 - 1s - loss: 0.0034 - accuracy: 0.8979 - val_loss: 6.6823e-04 - val_accuracy: 0.9780\n",
      "Epoch 4/50\n",
      "2360/2360 - 1s - loss: 0.0024 - accuracy: 0.8975 - val_loss: 0.0016 - val_accuracy: 0.8390\n",
      "Epoch 5/50\n",
      "2360/2360 - 1s - loss: 0.0019 - accuracy: 0.9216 - val_loss: 0.0011 - val_accuracy: 0.8966\n",
      "738/1 - 0s - loss: 5.1965e-04 - accuracy: 0.9133\n",
      "[0.16983050847457626, 0.8301694915254237]\n",
      "Train on 2360 samples, validate on 590 samples\n",
      "Epoch 1/50\n",
      "2360/2360 - 2s - loss: 0.1014 - accuracy: 0.6415 - val_loss: 0.0769 - val_accuracy: 0.8254\n",
      "Epoch 2/50\n",
      "2360/2360 - 1s - loss: 0.0824 - accuracy: 0.7386 - val_loss: 0.0779 - val_accuracy: 0.8576\n",
      "Epoch 3/50\n",
      "2360/2360 - 1s - loss: 0.0729 - accuracy: 0.7814 - val_loss: 0.0708 - val_accuracy: 0.8119\n",
      "Epoch 4/50\n",
      "2360/2360 - 1s - loss: 0.0683 - accuracy: 0.7864 - val_loss: 0.0693 - val_accuracy: 0.8593\n",
      "Epoch 5/50\n",
      "2360/2360 - 1s - loss: 0.0615 - accuracy: 0.8174 - val_loss: 0.0682 - val_accuracy: 0.8525\n",
      "Epoch 6/50\n",
      "2360/2360 - 1s - loss: 0.0573 - accuracy: 0.8297 - val_loss: 0.0688 - val_accuracy: 0.8407\n",
      "Epoch 7/50\n",
      "2360/2360 - 1s - loss: 0.0534 - accuracy: 0.8449 - val_loss: 0.0671 - val_accuracy: 0.8153\n",
      "Epoch 8/50\n",
      "2360/2360 - 1s - loss: 0.0467 - accuracy: 0.8716 - val_loss: 0.0660 - val_accuracy: 0.8169\n",
      "Epoch 9/50\n",
      "2360/2360 - 1s - loss: 0.0474 - accuracy: 0.8470 - val_loss: 0.0672 - val_accuracy: 0.7814\n",
      "Epoch 10/50\n",
      "2360/2360 - 1s - loss: 0.0428 - accuracy: 0.8826 - val_loss: 0.0664 - val_accuracy: 0.8373\n",
      "738/1 - 0s - loss: 0.0550 - accuracy: 0.8184\n",
      "[0.04135593220338983, 0.9586440677966102]\n",
      "Train on 2360 samples, validate on 590 samples\n",
      "Epoch 1/50\n",
      "2360/2360 - 2s - loss: 0.0428 - accuracy: 0.5898 - val_loss: 0.0355 - val_accuracy: 0.0847\n",
      "Epoch 2/50\n",
      "2360/2360 - 1s - loss: 0.0290 - accuracy: 0.6114 - val_loss: 0.0323 - val_accuracy: 0.1102\n",
      "Epoch 3/50\n",
      "2360/2360 - 1s - loss: 0.0256 - accuracy: 0.6453 - val_loss: 0.0289 - val_accuracy: 0.3424\n",
      "Epoch 4/50\n",
      "2360/2360 - 1s - loss: 0.0245 - accuracy: 0.6733 - val_loss: 0.0276 - val_accuracy: 0.4898\n",
      "Epoch 5/50\n",
      "2360/2360 - 1s - loss: 0.0218 - accuracy: 0.7106 - val_loss: 0.0300 - val_accuracy: 0.7475\n",
      "Epoch 6/50\n",
      "2360/2360 - 1s - loss: 0.0209 - accuracy: 0.7436 - val_loss: 0.0319 - val_accuracy: 0.7458\n",
      "738/1 - 0s - loss: 0.0162 - accuracy: 0.8062\n",
      "[0.05322033898305085, 0.9467796610169491]\n",
      "Train on 2360 samples, validate on 590 samples\n",
      "Epoch 1/50\n",
      "2360/2360 - 2s - loss: 0.0456 - accuracy: 0.6788 - val_loss: 0.0130 - val_accuracy: 0.8475\n",
      "Epoch 2/50\n",
      "2360/2360 - 1s - loss: 0.0227 - accuracy: 0.8119 - val_loss: 0.0084 - val_accuracy: 0.9390\n",
      "Epoch 3/50\n",
      "2360/2360 - 1s - loss: 0.0168 - accuracy: 0.8538 - val_loss: 0.0072 - val_accuracy: 0.9424\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4/50\n",
      "2360/2360 - 1s - loss: 0.0156 - accuracy: 0.8708 - val_loss: 0.0078 - val_accuracy: 0.9034\n",
      "Epoch 5/50\n",
      "2360/2360 - 1s - loss: 0.0116 - accuracy: 0.8958 - val_loss: 0.0049 - val_accuracy: 0.9746\n",
      "Epoch 6/50\n",
      "2360/2360 - 1s - loss: 0.0113 - accuracy: 0.9157 - val_loss: 0.0055 - val_accuracy: 0.9492\n",
      "Epoch 7/50\n",
      "2360/2360 - 1s - loss: 0.0097 - accuracy: 0.9292 - val_loss: 0.0055 - val_accuracy: 0.9525\n",
      "738/1 - 0s - loss: 0.0087 - accuracy: 0.9553\n",
      "[0.40779661016949154, 0.5922033898305085]\n",
      "Train on 2360 samples, validate on 590 samples\n",
      "Epoch 1/50\n",
      "2360/2360 - 2s - loss: 0.1804 - accuracy: 0.6280 - val_loss: 0.1327 - val_accuracy: 0.7237\n",
      "Epoch 2/50\n",
      "2360/2360 - 1s - loss: 0.1370 - accuracy: 0.7017 - val_loss: 0.1310 - val_accuracy: 0.7390\n",
      "Epoch 3/50\n",
      "2360/2360 - 1s - loss: 0.1251 - accuracy: 0.7492 - val_loss: 0.1288 - val_accuracy: 0.7797\n",
      "Epoch 4/50\n",
      "2360/2360 - 1s - loss: 0.1109 - accuracy: 0.7831 - val_loss: 0.1166 - val_accuracy: 0.7678\n",
      "Epoch 5/50\n",
      "2360/2360 - 1s - loss: 0.1037 - accuracy: 0.8030 - val_loss: 0.1144 - val_accuracy: 0.7847\n",
      "Epoch 6/50\n",
      "2360/2360 - 1s - loss: 0.0934 - accuracy: 0.8216 - val_loss: 0.1146 - val_accuracy: 0.7508\n",
      "Epoch 7/50\n",
      "2360/2360 - 1s - loss: 0.0872 - accuracy: 0.8496 - val_loss: 0.1138 - val_accuracy: 0.7576\n",
      "Epoch 8/50\n",
      "2360/2360 - 1s - loss: 0.0802 - accuracy: 0.8640 - val_loss: 0.1094 - val_accuracy: 0.7915\n",
      "Epoch 9/50\n",
      "2360/2360 - 1s - loss: 0.0724 - accuracy: 0.8792 - val_loss: 0.1124 - val_accuracy: 0.7864\n",
      "Epoch 10/50\n",
      "2360/2360 - 1s - loss: 0.0667 - accuracy: 0.8898 - val_loss: 0.1206 - val_accuracy: 0.8051\n",
      "738/1 - 0s - loss: 0.0696 - accuracy: 0.8049\n",
      "[0.3227118644067797, 0.6772881355932203]\n",
      "Train on 2360 samples, validate on 590 samples\n",
      "Epoch 1/50\n",
      "2360/2360 - 2s - loss: 0.1714 - accuracy: 0.5970 - val_loss: 0.1307 - val_accuracy: 0.5847\n",
      "Epoch 2/50\n",
      "2360/2360 - 1s - loss: 0.1228 - accuracy: 0.7144 - val_loss: 0.1041 - val_accuracy: 0.7814\n",
      "Epoch 3/50\n",
      "2360/2360 - 1s - loss: 0.1090 - accuracy: 0.7775 - val_loss: 0.0980 - val_accuracy: 0.7678\n",
      "Epoch 4/50\n",
      "2360/2360 - 1s - loss: 0.0924 - accuracy: 0.8110 - val_loss: 0.0879 - val_accuracy: 0.8085\n",
      "Epoch 5/50\n",
      "2360/2360 - 1s - loss: 0.0832 - accuracy: 0.8326 - val_loss: 0.0830 - val_accuracy: 0.8339\n",
      "Epoch 6/50\n",
      "2360/2360 - 1s - loss: 0.0741 - accuracy: 0.8576 - val_loss: 0.0815 - val_accuracy: 0.8492\n",
      "Epoch 7/50\n",
      "2360/2360 - 1s - loss: 0.0707 - accuracy: 0.8699 - val_loss: 0.0763 - val_accuracy: 0.8407\n",
      "Epoch 8/50\n",
      "2360/2360 - 1s - loss: 0.0612 - accuracy: 0.8864 - val_loss: 0.0777 - val_accuracy: 0.8695\n",
      "Epoch 9/50\n",
      "2360/2360 - 1s - loss: 0.0575 - accuracy: 0.8919 - val_loss: 0.0756 - val_accuracy: 0.8475\n",
      "Epoch 10/50\n",
      "2360/2360 - 1s - loss: 0.0488 - accuracy: 0.9089 - val_loss: 0.0805 - val_accuracy: 0.8729\n",
      "Epoch 11/50\n",
      "2360/2360 - 1s - loss: 0.0441 - accuracy: 0.9246 - val_loss: 0.0740 - val_accuracy: 0.8729\n",
      "Epoch 12/50\n",
      "2360/2360 - 1s - loss: 0.0395 - accuracy: 0.9347 - val_loss: 0.0752 - val_accuracy: 0.8475\n",
      "Epoch 13/50\n",
      "2360/2360 - 1s - loss: 0.0383 - accuracy: 0.9335 - val_loss: 0.0795 - val_accuracy: 0.8593\n",
      "738/1 - 0s - loss: 0.0472 - accuracy: 0.8347\n",
      "[0.17559322033898306, 0.8244067796610169]\n",
      "Train on 2360 samples, validate on 590 samples\n",
      "Epoch 1/50\n",
      "2360/2360 - 2s - loss: 0.1182 - accuracy: 0.5919 - val_loss: 0.0839 - val_accuracy: 0.6881\n",
      "Epoch 2/50\n",
      "2360/2360 - 1s - loss: 0.0930 - accuracy: 0.6733 - val_loss: 0.0831 - val_accuracy: 0.8525\n",
      "Epoch 3/50\n",
      "2360/2360 - 1s - loss: 0.0882 - accuracy: 0.6932 - val_loss: 0.0771 - val_accuracy: 0.7254\n",
      "Epoch 4/50\n",
      "2360/2360 - 1s - loss: 0.0801 - accuracy: 0.7436 - val_loss: 0.0740 - val_accuracy: 0.7831\n",
      "Epoch 5/50\n",
      "2360/2360 - 1s - loss: 0.0761 - accuracy: 0.7568 - val_loss: 0.0752 - val_accuracy: 0.8373\n",
      "Epoch 6/50\n",
      "2360/2360 - 1s - loss: 0.0723 - accuracy: 0.7814 - val_loss: 0.0739 - val_accuracy: 0.8119\n",
      "Epoch 7/50\n",
      "2360/2360 - 1s - loss: 0.0697 - accuracy: 0.7911 - val_loss: 0.0737 - val_accuracy: 0.8051\n",
      "Epoch 8/50\n",
      "2360/2360 - 1s - loss: 0.0612 - accuracy: 0.8216 - val_loss: 0.0758 - val_accuracy: 0.8254\n",
      "Epoch 9/50\n",
      "2360/2360 - 1s - loss: 0.0574 - accuracy: 0.8254 - val_loss: 0.0741 - val_accuracy: 0.7644\n",
      "738/1 - 0s - loss: 0.0525 - accuracy: 0.7751\n",
      "[0.1511864406779661, 0.848813559322034]\n",
      "Train on 2360 samples, validate on 590 samples\n",
      "Epoch 1/50\n",
      "2360/2360 - 2s - loss: 0.1139 - accuracy: 0.5208 - val_loss: 0.0965 - val_accuracy: 0.7915\n",
      "Epoch 2/50\n",
      "2360/2360 - 1s - loss: 0.0889 - accuracy: 0.5856 - val_loss: 0.0898 - val_accuracy: 0.5051\n",
      "Epoch 3/50\n",
      "2360/2360 - 1s - loss: 0.0837 - accuracy: 0.5907 - val_loss: 0.0908 - val_accuracy: 0.6407\n",
      "Epoch 4/50\n",
      "2360/2360 - 1s - loss: 0.0790 - accuracy: 0.6564 - val_loss: 0.0888 - val_accuracy: 0.6390\n",
      "Epoch 5/50\n",
      "2360/2360 - 1s - loss: 0.0763 - accuracy: 0.6869 - val_loss: 0.0894 - val_accuracy: 0.7254\n",
      "Epoch 6/50\n",
      "2360/2360 - 1s - loss: 0.0757 - accuracy: 0.6941 - val_loss: 0.0929 - val_accuracy: 0.7712\n",
      "738/1 - 0s - loss: 0.0504 - accuracy: 0.8022\n",
      "[0.08203389830508474, 0.9179661016949152]\n",
      "Train on 2360 samples, validate on 590 samples\n",
      "Epoch 1/50\n",
      "2360/2360 - 2s - loss: 0.0513 - accuracy: 0.7021 - val_loss: 0.0313 - val_accuracy: 0.9119\n",
      "Epoch 2/50\n",
      "2360/2360 - 1s - loss: 0.0302 - accuracy: 0.8246 - val_loss: 0.0256 - val_accuracy: 0.8814\n",
      "Epoch 3/50\n",
      "2360/2360 - 1s - loss: 0.0267 - accuracy: 0.8661 - val_loss: 0.0247 - val_accuracy: 0.8492\n",
      "Epoch 4/50\n",
      "2360/2360 - 1s - loss: 0.0194 - accuracy: 0.9038 - val_loss: 0.0237 - val_accuracy: 0.9254\n",
      "Epoch 5/50\n",
      "2360/2360 - 1s - loss: 0.0172 - accuracy: 0.9013 - val_loss: 0.0236 - val_accuracy: 0.9220\n",
      "Epoch 6/50\n",
      "2360/2360 - 1s - loss: 0.0152 - accuracy: 0.9271 - val_loss: 0.0233 - val_accuracy: 0.9102\n",
      "Epoch 7/50\n",
      "2360/2360 - 1s - loss: 0.0118 - accuracy: 0.9441 - val_loss: 0.0238 - val_accuracy: 0.9237\n",
      "Epoch 8/50\n",
      "2360/2360 - 1s - loss: 0.0117 - accuracy: 0.9530 - val_loss: 0.0244 - val_accuracy: 0.9356\n",
      "738/1 - 0s - loss: 0.0073 - accuracy: 0.9444\n",
      "[0.06271186440677966, 0.9372881355932203]\n",
      "Train on 2360 samples, validate on 590 samples\n",
      "Epoch 1/50\n",
      "2360/2360 - 2s - loss: 0.0522 - accuracy: 0.5928 - val_loss: 0.0456 - val_accuracy: 0.8915\n",
      "Epoch 2/50\n",
      "2360/2360 - 1s - loss: 0.0361 - accuracy: 0.6699 - val_loss: 0.0369 - val_accuracy: 0.8153\n",
      "Epoch 3/50\n",
      "2360/2360 - 1s - loss: 0.0277 - accuracy: 0.7818 - val_loss: 0.0331 - val_accuracy: 0.7763\n",
      "Epoch 4/50\n",
      "2360/2360 - 1s - loss: 0.0239 - accuracy: 0.8068 - val_loss: 0.0342 - val_accuracy: 0.8356\n",
      "Epoch 5/50\n",
      "2360/2360 - 1s - loss: 0.0209 - accuracy: 0.8508 - val_loss: 0.0305 - val_accuracy: 0.7153\n",
      "Epoch 6/50\n",
      "2360/2360 - 1s - loss: 0.0182 - accuracy: 0.8661 - val_loss: 0.0315 - val_accuracy: 0.8237\n",
      "Epoch 7/50\n",
      "2360/2360 - 1s - loss: 0.0159 - accuracy: 0.8814 - val_loss: 0.0327 - val_accuracy: 0.8458\n",
      "738/1 - 0s - loss: 0.0317 - accuracy: 0.8659\n",
      "[0.09966101694915254, 0.9003389830508475]\n",
      "Train on 2360 samples, validate on 590 samples\n",
      "Epoch 1/50\n",
      "2360/2360 - 2s - loss: 0.0751 - accuracy: 0.5686 - val_loss: 0.0591 - val_accuracy: 0.9169\n",
      "Epoch 2/50\n",
      "2360/2360 - 1s - loss: 0.0527 - accuracy: 0.7267 - val_loss: 0.0453 - val_accuracy: 0.9017\n",
      "Epoch 3/50\n",
      "2360/2360 - 1s - loss: 0.0446 - accuracy: 0.7983 - val_loss: 0.0422 - val_accuracy: 0.9119\n",
      "Epoch 4/50\n",
      "2360/2360 - 1s - loss: 0.0399 - accuracy: 0.8521 - val_loss: 0.0380 - val_accuracy: 0.8780\n",
      "Epoch 5/50\n",
      "2360/2360 - 1s - loss: 0.0362 - accuracy: 0.8487 - val_loss: 0.0364 - val_accuracy: 0.8915\n",
      "Epoch 6/50\n",
      "2360/2360 - 1s - loss: 0.0344 - accuracy: 0.8699 - val_loss: 0.0356 - val_accuracy: 0.8814\n",
      "Epoch 7/50\n",
      "2360/2360 - 1s - loss: 0.0300 - accuracy: 0.8852 - val_loss: 0.0358 - val_accuracy: 0.9000\n",
      "Epoch 8/50\n",
      "2360/2360 - 1s - loss: 0.0259 - accuracy: 0.9034 - val_loss: 0.0343 - val_accuracy: 0.8881\n",
      "Epoch 9/50\n",
      "2360/2360 - 1s - loss: 0.0250 - accuracy: 0.9055 - val_loss: 0.0344 - val_accuracy: 0.9136\n",
      "Epoch 10/50\n",
      "2360/2360 - 1s - loss: 0.0242 - accuracy: 0.9064 - val_loss: 0.0370 - val_accuracy: 0.9153\n",
      "738/1 - 0s - loss: 0.0225 - accuracy: 0.9119\n",
      "[0.09627118644067796, 0.903728813559322]\n",
      "Train on 2360 samples, validate on 590 samples\n",
      "Epoch 1/50\n",
      "2360/2360 - 2s - loss: 0.0647 - accuracy: 0.6419 - val_loss: 0.0479 - val_accuracy: 0.5119\n",
      "Epoch 2/50\n",
      "2360/2360 - 1s - loss: 0.0380 - accuracy: 0.7924 - val_loss: 0.0386 - val_accuracy: 0.7390\n",
      "Epoch 3/50\n",
      "2360/2360 - 1s - loss: 0.0290 - accuracy: 0.8538 - val_loss: 0.0361 - val_accuracy: 0.7576\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4/50\n",
      "2360/2360 - 1s - loss: 0.0243 - accuracy: 0.8970 - val_loss: 0.0371 - val_accuracy: 0.7254\n",
      "Epoch 5/50\n",
      "2360/2360 - 1s - loss: 0.0210 - accuracy: 0.9021 - val_loss: 0.0336 - val_accuracy: 0.7644\n",
      "Epoch 6/50\n",
      "2360/2360 - 1s - loss: 0.0169 - accuracy: 0.9233 - val_loss: 0.0298 - val_accuracy: 0.8356\n",
      "Epoch 7/50\n",
      "2360/2360 - 1s - loss: 0.0156 - accuracy: 0.9390 - val_loss: 0.0292 - val_accuracy: 0.8881\n",
      "Epoch 8/50\n",
      "2360/2360 - 1s - loss: 0.0117 - accuracy: 0.9589 - val_loss: 0.0285 - val_accuracy: 0.8797\n",
      "Epoch 9/50\n",
      "2360/2360 - 1s - loss: 0.0104 - accuracy: 0.9682 - val_loss: 0.0291 - val_accuracy: 0.8305\n",
      "Epoch 10/50\n",
      "2360/2360 - 1s - loss: 0.0104 - accuracy: 0.9648 - val_loss: 0.0280 - val_accuracy: 0.9203\n",
      "Epoch 11/50\n",
      "2360/2360 - 1s - loss: 0.0088 - accuracy: 0.9725 - val_loss: 0.0293 - val_accuracy: 0.9102\n",
      "Epoch 12/50\n",
      "2360/2360 - 1s - loss: 0.0078 - accuracy: 0.9763 - val_loss: 0.0324 - val_accuracy: 0.9458\n",
      "738/1 - 0s - loss: 0.0275 - accuracy: 0.9634\n",
      "[0.009152542372881356, 0.9908474576271187]\n",
      "Train on 2360 samples, validate on 590 samples\n",
      "Epoch 1/50\n",
      "2360/2360 - 2s - loss: 0.0173 - accuracy: 0.7797 - val_loss: 0.0020 - val_accuracy: 0.9051\n",
      "Epoch 2/50\n",
      "2360/2360 - 1s - loss: 0.0019 - accuracy: 0.8835 - val_loss: 0.0010 - val_accuracy: 0.9797\n",
      "Epoch 3/50\n",
      "2360/2360 - 1s - loss: 0.0035 - accuracy: 0.9220 - val_loss: 0.0024 - val_accuracy: 0.7915\n",
      "Epoch 4/50\n",
      "2360/2360 - 1s - loss: 0.0033 - accuracy: 0.8737 - val_loss: 5.0779e-04 - val_accuracy: 0.9746\n",
      "Epoch 5/50\n",
      "2360/2360 - 1s - loss: 0.0016 - accuracy: 0.9415 - val_loss: 3.8172e-04 - val_accuracy: 0.9797\n",
      "Epoch 6/50\n",
      "2360/2360 - 1s - loss: 6.7707e-04 - accuracy: 0.9695 - val_loss: 2.0046e-04 - val_accuracy: 0.9831\n",
      "Epoch 7/50\n",
      "2360/2360 - 1s - loss: 5.5286e-04 - accuracy: 0.9788 - val_loss: 2.1336e-04 - val_accuracy: 0.9814\n",
      "Epoch 8/50\n",
      "2360/2360 - 1s - loss: 0.0014 - accuracy: 0.9517 - val_loss: 0.0013 - val_accuracy: 0.8932\n",
      "738/1 - 0s - loss: 6.6078e-04 - accuracy: 0.8930\n",
      "[0.16983050847457626, 0.8301694915254237]\n",
      "Train on 2360 samples, validate on 590 samples\n",
      "Epoch 1/50\n",
      "2360/2360 - 3s - loss: 0.1055 - accuracy: 0.6360 - val_loss: 0.0803 - val_accuracy: 0.8424\n",
      "Epoch 2/50\n",
      "2360/2360 - 1s - loss: 0.0802 - accuracy: 0.7288 - val_loss: 0.0770 - val_accuracy: 0.8644\n",
      "Epoch 3/50\n",
      "2360/2360 - 1s - loss: 0.0723 - accuracy: 0.7784 - val_loss: 0.0705 - val_accuracy: 0.8169\n",
      "Epoch 4/50\n",
      "2360/2360 - 1s - loss: 0.0664 - accuracy: 0.7932 - val_loss: 0.0683 - val_accuracy: 0.7983\n",
      "Epoch 5/50\n",
      "2360/2360 - 1s - loss: 0.0603 - accuracy: 0.8267 - val_loss: 0.0651 - val_accuracy: 0.8186\n",
      "Epoch 6/50\n",
      "2360/2360 - 1s - loss: 0.0570 - accuracy: 0.8292 - val_loss: 0.0669 - val_accuracy: 0.7983\n",
      "Epoch 7/50\n",
      "2360/2360 - 1s - loss: 0.0556 - accuracy: 0.8343 - val_loss: 0.0694 - val_accuracy: 0.8525\n",
      "738/1 - 0s - loss: 0.0453 - accuracy: 0.8428\n",
      "[0.04135593220338983, 0.9586440677966102]\n",
      "Train on 2360 samples, validate on 590 samples\n",
      "Epoch 1/50\n",
      "2360/2360 - 2s - loss: 0.0424 - accuracy: 0.5441 - val_loss: 0.0332 - val_accuracy: 0.9203\n",
      "Epoch 2/50\n",
      "2360/2360 - 1s - loss: 0.0289 - accuracy: 0.6157 - val_loss: 0.0299 - val_accuracy: 0.2407\n",
      "Epoch 3/50\n",
      "2360/2360 - 1s - loss: 0.0267 - accuracy: 0.6106 - val_loss: 0.0287 - val_accuracy: 0.7169\n",
      "Epoch 4/50\n",
      "2360/2360 - 1s - loss: 0.0253 - accuracy: 0.6665 - val_loss: 0.0315 - val_accuracy: 0.8153\n",
      "Epoch 5/50\n",
      "2360/2360 - 1s - loss: 0.0258 - accuracy: 0.6237 - val_loss: 0.0276 - val_accuracy: 0.5288\n",
      "Epoch 6/50\n",
      "2360/2360 - 1s - loss: 0.0233 - accuracy: 0.7042 - val_loss: 0.0271 - val_accuracy: 0.6881\n",
      "Epoch 7/50\n",
      "2360/2360 - 1s - loss: 0.0217 - accuracy: 0.7051 - val_loss: 0.0269 - val_accuracy: 0.6220\n",
      "Epoch 8/50\n",
      "2360/2360 - 1s - loss: 0.0210 - accuracy: 0.7585 - val_loss: 0.0264 - val_accuracy: 0.4797\n",
      "Epoch 9/50\n",
      "2360/2360 - 1s - loss: 0.0167 - accuracy: 0.7975 - val_loss: 0.0264 - val_accuracy: 0.7932\n",
      "Epoch 10/50\n",
      "2360/2360 - 1s - loss: 0.0149 - accuracy: 0.8403 - val_loss: 0.0262 - val_accuracy: 0.7000\n",
      "Epoch 11/50\n",
      "2360/2360 - 1s - loss: 0.0149 - accuracy: 0.8169 - val_loss: 0.0238 - val_accuracy: 0.6305\n",
      "Epoch 12/50\n",
      "2360/2360 - 1s - loss: 0.0121 - accuracy: 0.8534 - val_loss: 0.0276 - val_accuracy: 0.8322\n",
      "Epoch 13/50\n",
      "2360/2360 - 1s - loss: 0.0117 - accuracy: 0.8797 - val_loss: 0.0232 - val_accuracy: 0.6220\n",
      "Epoch 14/50\n",
      "2360/2360 - 1s - loss: 0.0101 - accuracy: 0.8958 - val_loss: 0.0272 - val_accuracy: 0.8593\n",
      "Epoch 15/50\n",
      "2360/2360 - 1s - loss: 0.0107 - accuracy: 0.8847 - val_loss: 0.0421 - val_accuracy: 0.9373\n",
      "738/1 - 0s - loss: 0.0224 - accuracy: 0.9593\n",
      "[0.05322033898305085, 0.9467796610169491]\n",
      "Train on 2360 samples, validate on 590 samples\n",
      "Epoch 1/50\n",
      "2360/2360 - 2s - loss: 0.0372 - accuracy: 0.7504 - val_loss: 0.0161 - val_accuracy: 0.7475\n",
      "Epoch 2/50\n",
      "2360/2360 - 1s - loss: 0.0223 - accuracy: 0.8394 - val_loss: 0.0121 - val_accuracy: 0.8017\n",
      "Epoch 3/50\n",
      "2360/2360 - 1s - loss: 0.0189 - accuracy: 0.8297 - val_loss: 0.0092 - val_accuracy: 0.8712\n",
      "Epoch 4/50\n",
      "2360/2360 - 1s - loss: 0.0140 - accuracy: 0.8869 - val_loss: 0.0062 - val_accuracy: 0.9542\n",
      "Epoch 5/50\n",
      "2360/2360 - 1s - loss: 0.0120 - accuracy: 0.9123 - val_loss: 0.0083 - val_accuracy: 0.8898\n",
      "Epoch 6/50\n",
      "2360/2360 - 1s - loss: 0.0087 - accuracy: 0.9292 - val_loss: 0.0062 - val_accuracy: 0.9288\n",
      "Epoch 7/50\n",
      "2360/2360 - 1s - loss: 0.0097 - accuracy: 0.9305 - val_loss: 0.0055 - val_accuracy: 0.9407\n",
      "Epoch 8/50\n",
      "2360/2360 - 1s - loss: 0.0067 - accuracy: 0.9458 - val_loss: 0.0051 - val_accuracy: 0.9441\n",
      "Epoch 9/50\n",
      "2360/2360 - 1s - loss: 0.0066 - accuracy: 0.9508 - val_loss: 0.0052 - val_accuracy: 0.9373\n",
      "Epoch 10/50\n",
      "2360/2360 - 1s - loss: 0.0043 - accuracy: 0.9606 - val_loss: 0.0043 - val_accuracy: 0.9610\n",
      "Epoch 11/50\n",
      "2360/2360 - 1s - loss: 0.0035 - accuracy: 0.9720 - val_loss: 0.0040 - val_accuracy: 0.9661\n",
      "Epoch 12/50\n",
      "2360/2360 - 1s - loss: 0.0034 - accuracy: 0.9822 - val_loss: 0.0049 - val_accuracy: 0.9492\n",
      "Epoch 13/50\n",
      "2360/2360 - 1s - loss: 0.0026 - accuracy: 0.9805 - val_loss: 0.0046 - val_accuracy: 0.9525\n",
      "738/1 - 0s - loss: 0.0103 - accuracy: 0.9472\n",
      "[0.40779661016949154, 0.5922033898305085]\n",
      "Train on 2360 samples, validate on 590 samples\n",
      "Epoch 1/50\n",
      "2360/2360 - 2s - loss: 0.1720 - accuracy: 0.6369 - val_loss: 0.1374 - val_accuracy: 0.7322\n",
      "Epoch 2/50\n",
      "2360/2360 - 1s - loss: 0.1396 - accuracy: 0.7042 - val_loss: 0.1260 - val_accuracy: 0.7525\n",
      "Epoch 3/50\n",
      "2360/2360 - 1s - loss: 0.1235 - accuracy: 0.7589 - val_loss: 0.1236 - val_accuracy: 0.7712\n",
      "Epoch 4/50\n",
      "2360/2360 - 1s - loss: 0.1122 - accuracy: 0.7894 - val_loss: 0.1205 - val_accuracy: 0.7847\n",
      "Epoch 5/50\n",
      "2360/2360 - 1s - loss: 0.1068 - accuracy: 0.7958 - val_loss: 0.1154 - val_accuracy: 0.7542\n",
      "Epoch 6/50\n",
      "2360/2360 - 1s - loss: 0.1014 - accuracy: 0.8169 - val_loss: 0.1121 - val_accuracy: 0.7915\n",
      "Epoch 7/50\n",
      "2360/2360 - 1s - loss: 0.0880 - accuracy: 0.8419 - val_loss: 0.1188 - val_accuracy: 0.7881\n",
      "Epoch 8/50\n",
      "2360/2360 - 1s - loss: 0.0848 - accuracy: 0.8504 - val_loss: 0.1296 - val_accuracy: 0.7966\n",
      "738/1 - 0s - loss: 0.0755 - accuracy: 0.7846\n",
      "[0.3227118644067797, 0.6772881355932203]\n",
      "Train on 2360 samples, validate on 590 samples\n",
      "Epoch 1/50\n",
      "2360/2360 - 2s - loss: 0.1700 - accuracy: 0.6343 - val_loss: 0.1149 - val_accuracy: 0.7271\n",
      "Epoch 2/50\n",
      "2360/2360 - 1s - loss: 0.1150 - accuracy: 0.7551 - val_loss: 0.1041 - val_accuracy: 0.7746\n",
      "Epoch 3/50\n",
      "2360/2360 - 1s - loss: 0.1006 - accuracy: 0.7890 - val_loss: 0.0980 - val_accuracy: 0.7712\n",
      "Epoch 4/50\n",
      "2360/2360 - 1s - loss: 0.0874 - accuracy: 0.8356 - val_loss: 0.0855 - val_accuracy: 0.8119\n",
      "Epoch 5/50\n",
      "2360/2360 - 1s - loss: 0.0777 - accuracy: 0.8458 - val_loss: 0.0811 - val_accuracy: 0.8305\n",
      "Epoch 6/50\n",
      "2360/2360 - 1s - loss: 0.0718 - accuracy: 0.8674 - val_loss: 0.0787 - val_accuracy: 0.8271\n",
      "Epoch 7/50\n",
      "2360/2360 - 1s - loss: 0.0613 - accuracy: 0.8890 - val_loss: 0.0774 - val_accuracy: 0.8153\n",
      "Epoch 8/50\n",
      "2360/2360 - 1s - loss: 0.0545 - accuracy: 0.9055 - val_loss: 0.0785 - val_accuracy: 0.8254\n",
      "Epoch 9/50\n",
      "2360/2360 - 1s - loss: 0.0485 - accuracy: 0.9136 - val_loss: 0.0753 - val_accuracy: 0.8542\n",
      "Epoch 10/50\n",
      "2360/2360 - 1s - loss: 0.0437 - accuracy: 0.9271 - val_loss: 0.0791 - val_accuracy: 0.8322\n",
      "Epoch 11/50\n",
      "2360/2360 - 1s - loss: 0.0384 - accuracy: 0.9403 - val_loss: 0.0738 - val_accuracy: 0.8492\n",
      "Epoch 12/50\n",
      "2360/2360 - 1s - loss: 0.0327 - accuracy: 0.9436 - val_loss: 0.0759 - val_accuracy: 0.8610\n",
      "Epoch 13/50\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2360/2360 - 1s - loss: 0.0318 - accuracy: 0.9462 - val_loss: 0.0748 - val_accuracy: 0.8729\n",
      "738/1 - 0s - loss: 0.0473 - accuracy: 0.8401\n",
      "[0.17559322033898306, 0.8244067796610169]\n",
      "Train on 2360 samples, validate on 590 samples\n",
      "Epoch 1/50\n",
      "2360/2360 - 2s - loss: 0.1196 - accuracy: 0.5890 - val_loss: 0.0824 - val_accuracy: 0.7542\n",
      "Epoch 2/50\n",
      "2360/2360 - 1s - loss: 0.0931 - accuracy: 0.6559 - val_loss: 0.0796 - val_accuracy: 0.7814\n",
      "Epoch 3/50\n",
      "2360/2360 - 1s - loss: 0.0846 - accuracy: 0.7089 - val_loss: 0.0773 - val_accuracy: 0.7559\n",
      "Epoch 4/50\n",
      "2360/2360 - 1s - loss: 0.0814 - accuracy: 0.7220 - val_loss: 0.0756 - val_accuracy: 0.7356\n",
      "Epoch 5/50\n",
      "2360/2360 - 1s - loss: 0.0749 - accuracy: 0.7653 - val_loss: 0.0784 - val_accuracy: 0.8169\n",
      "Epoch 6/50\n",
      "2360/2360 - 1s - loss: 0.0722 - accuracy: 0.7542 - val_loss: 0.0736 - val_accuracy: 0.7983\n",
      "Epoch 7/50\n",
      "2360/2360 - 1s - loss: 0.0717 - accuracy: 0.7695 - val_loss: 0.0776 - val_accuracy: 0.8339\n",
      "Epoch 8/50\n",
      "2360/2360 - 1s - loss: 0.0636 - accuracy: 0.8034 - val_loss: 0.0712 - val_accuracy: 0.8085\n",
      "Epoch 9/50\n",
      "2360/2360 - 1s - loss: 0.0576 - accuracy: 0.8360 - val_loss: 0.0703 - val_accuracy: 0.7898\n",
      "Epoch 10/50\n",
      "2360/2360 - 1s - loss: 0.0558 - accuracy: 0.8398 - val_loss: 0.0726 - val_accuracy: 0.8136\n",
      "Epoch 11/50\n",
      "2360/2360 - 1s - loss: 0.0507 - accuracy: 0.8504 - val_loss: 0.0707 - val_accuracy: 0.8051\n",
      "738/1 - 0s - loss: 0.0495 - accuracy: 0.8062\n",
      "[0.1511864406779661, 0.848813559322034]\n",
      "Train on 2360 samples, validate on 590 samples\n",
      "Epoch 1/50\n",
      "2360/2360 - 2s - loss: 0.1185 - accuracy: 0.5610 - val_loss: 0.0920 - val_accuracy: 0.4153\n",
      "Epoch 2/50\n",
      "2360/2360 - 1s - loss: 0.0884 - accuracy: 0.6021 - val_loss: 0.0884 - val_accuracy: 0.6390\n",
      "Epoch 3/50\n",
      "2360/2360 - 1s - loss: 0.0816 - accuracy: 0.6559 - val_loss: 0.0871 - val_accuracy: 0.4186\n",
      "Epoch 4/50\n",
      "2360/2360 - 1s - loss: 0.0784 - accuracy: 0.6581 - val_loss: 0.0871 - val_accuracy: 0.7119\n",
      "Epoch 5/50\n",
      "2360/2360 - 1s - loss: 0.0741 - accuracy: 0.7186 - val_loss: 0.0859 - val_accuracy: 0.6695\n",
      "Epoch 6/50\n",
      "2360/2360 - 1s - loss: 0.0727 - accuracy: 0.7076 - val_loss: 0.0871 - val_accuracy: 0.6322\n",
      "Epoch 7/50\n",
      "2360/2360 - 1s - loss: 0.0708 - accuracy: 0.7157 - val_loss: 0.0863 - val_accuracy: 0.6288\n",
      "738/1 - 0s - loss: 0.0482 - accuracy: 0.6518\n",
      "[0.08203389830508474, 0.9179661016949152]\n",
      "Train on 2360 samples, validate on 590 samples\n",
      "Epoch 1/50\n",
      "2360/2360 - 2s - loss: 0.0477 - accuracy: 0.6826 - val_loss: 0.0294 - val_accuracy: 0.8407\n",
      "Epoch 2/50\n",
      "2360/2360 - 1s - loss: 0.0276 - accuracy: 0.8398 - val_loss: 0.0266 - val_accuracy: 0.8983\n",
      "Epoch 3/50\n",
      "2360/2360 - 1s - loss: 0.0225 - accuracy: 0.8822 - val_loss: 0.0266 - val_accuracy: 0.9119\n",
      "Epoch 4/50\n",
      "2360/2360 - 1s - loss: 0.0183 - accuracy: 0.9025 - val_loss: 0.0239 - val_accuracy: 0.8932\n",
      "Epoch 5/50\n",
      "2360/2360 - 1s - loss: 0.0191 - accuracy: 0.9008 - val_loss: 0.0256 - val_accuracy: 0.9203\n",
      "Epoch 6/50\n",
      "2360/2360 - 1s - loss: 0.0142 - accuracy: 0.9326 - val_loss: 0.0239 - val_accuracy: 0.9203\n",
      "Epoch 7/50\n",
      "2360/2360 - 1s - loss: 0.0131 - accuracy: 0.9352 - val_loss: 0.0251 - val_accuracy: 0.9407\n",
      "Epoch 8/50\n",
      "2360/2360 - 1s - loss: 0.0109 - accuracy: 0.9475 - val_loss: 0.0315 - val_accuracy: 0.9542\n",
      "738/1 - 0s - loss: 0.0117 - accuracy: 0.9607\n",
      "[0.06271186440677966, 0.9372881355932203]\n",
      "Train on 2360 samples, validate on 590 samples\n",
      "Epoch 1/50\n",
      "2360/2360 - 2s - loss: 0.0469 - accuracy: 0.6055 - val_loss: 0.0384 - val_accuracy: 0.2983\n",
      "Epoch 2/50\n",
      "2360/2360 - 1s - loss: 0.0371 - accuracy: 0.6703 - val_loss: 0.0333 - val_accuracy: 0.6186\n",
      "Epoch 3/50\n",
      "2360/2360 - 1s - loss: 0.0299 - accuracy: 0.7538 - val_loss: 0.0319 - val_accuracy: 0.8288\n",
      "Epoch 4/50\n",
      "2360/2360 - 1s - loss: 0.0239 - accuracy: 0.8199 - val_loss: 0.0317 - val_accuracy: 0.5915\n",
      "Epoch 5/50\n",
      "2360/2360 - 1s - loss: 0.0208 - accuracy: 0.8436 - val_loss: 0.0278 - val_accuracy: 0.8085\n",
      "Epoch 6/50\n",
      "2360/2360 - 1s - loss: 0.0172 - accuracy: 0.8970 - val_loss: 0.0288 - val_accuracy: 0.8508\n",
      "Epoch 7/50\n",
      "2360/2360 - 1s - loss: 0.0155 - accuracy: 0.8936 - val_loss: 0.0292 - val_accuracy: 0.8780\n",
      "738/1 - 0s - loss: 0.0301 - accuracy: 0.8740\n",
      "[0.09966101694915254, 0.9003389830508475]\n",
      "Train on 2360 samples, validate on 590 samples\n",
      "Epoch 1/50\n",
      "2360/2360 - 3s - loss: 0.0730 - accuracy: 0.6148 - val_loss: 0.0644 - val_accuracy: 0.9288\n",
      "Epoch 2/50\n",
      "2360/2360 - 1s - loss: 0.0484 - accuracy: 0.7788 - val_loss: 0.0425 - val_accuracy: 0.9068\n",
      "Epoch 3/50\n",
      "2360/2360 - 1s - loss: 0.0426 - accuracy: 0.7949 - val_loss: 0.0385 - val_accuracy: 0.8644\n",
      "Epoch 4/50\n",
      "2360/2360 - 1s - loss: 0.0378 - accuracy: 0.8483 - val_loss: 0.0421 - val_accuracy: 0.9136\n",
      "Epoch 5/50\n",
      "2360/2360 - 1s - loss: 0.0340 - accuracy: 0.8534 - val_loss: 0.0437 - val_accuracy: 0.9203\n",
      "738/1 - 0s - loss: 0.0228 - accuracy: 0.9295\n",
      "[0.09627118644067796, 0.903728813559322]\n",
      "Train on 2360 samples, validate on 590 samples\n",
      "Epoch 1/50\n",
      "2360/2360 - 2s - loss: 0.0563 - accuracy: 0.6390 - val_loss: 0.0424 - val_accuracy: 0.7288\n",
      "Epoch 2/50\n",
      "2360/2360 - 1s - loss: 0.0369 - accuracy: 0.8148 - val_loss: 0.0378 - val_accuracy: 0.7542\n",
      "Epoch 3/50\n",
      "2360/2360 - 1s - loss: 0.0290 - accuracy: 0.8631 - val_loss: 0.0332 - val_accuracy: 0.7949\n",
      "Epoch 4/50\n",
      "2360/2360 - 1s - loss: 0.0250 - accuracy: 0.8919 - val_loss: 0.0331 - val_accuracy: 0.7661\n",
      "Epoch 5/50\n",
      "2360/2360 - 1s - loss: 0.0208 - accuracy: 0.9114 - val_loss: 0.0291 - val_accuracy: 0.8678\n",
      "Epoch 6/50\n",
      "2360/2360 - 1s - loss: 0.0160 - accuracy: 0.9373 - val_loss: 0.0286 - val_accuracy: 0.8542\n",
      "Epoch 7/50\n",
      "2360/2360 - 1s - loss: 0.0123 - accuracy: 0.9581 - val_loss: 0.0288 - val_accuracy: 0.9373\n",
      "Epoch 8/50\n",
      "2360/2360 - 1s - loss: 0.0133 - accuracy: 0.9564 - val_loss: 0.0260 - val_accuracy: 0.9492\n",
      "Epoch 9/50\n",
      "2360/2360 - 1s - loss: 0.0093 - accuracy: 0.9737 - val_loss: 0.0250 - val_accuracy: 0.9051\n",
      "Epoch 10/50\n",
      "2360/2360 - 1s - loss: 0.0078 - accuracy: 0.9763 - val_loss: 0.0243 - val_accuracy: 0.8966\n",
      "Epoch 11/50\n",
      "2360/2360 - 1s - loss: 0.0075 - accuracy: 0.9758 - val_loss: 0.0304 - val_accuracy: 0.9508\n",
      "Epoch 12/50\n",
      "2360/2360 - 1s - loss: 0.0054 - accuracy: 0.9843 - val_loss: 0.0339 - val_accuracy: 0.9593\n",
      "738/1 - 0s - loss: 0.0274 - accuracy: 0.9621\n",
      "[0.009152542372881356, 0.9908474576271187]\n",
      "Train on 2360 samples, validate on 590 samples\n",
      "Epoch 1/50\n",
      "2360/2360 - 2s - loss: 0.0101 - accuracy: 0.7737 - val_loss: 0.0022 - val_accuracy: 0.9254\n",
      "Epoch 2/50\n",
      "2360/2360 - 1s - loss: 0.0029 - accuracy: 0.8669 - val_loss: 0.0016 - val_accuracy: 0.8797\n",
      "Epoch 3/50\n",
      "2360/2360 - 1s - loss: 0.0027 - accuracy: 0.9208 - val_loss: 0.0035 - val_accuracy: 0.6898\n",
      "Epoch 4/50\n",
      "2360/2360 - 1s - loss: 0.0020 - accuracy: 0.8754 - val_loss: 0.0012 - val_accuracy: 0.9068\n",
      "Epoch 5/50\n",
      "2360/2360 - 1s - loss: 0.0013 - accuracy: 0.9309 - val_loss: 7.2596e-04 - val_accuracy: 0.9441\n",
      "Epoch 6/50\n",
      "2360/2360 - 1s - loss: 0.0010 - accuracy: 0.9559 - val_loss: 5.7810e-04 - val_accuracy: 0.9525\n",
      "Epoch 7/50\n",
      "2360/2360 - 1s - loss: 0.0021 - accuracy: 0.9034 - val_loss: 5.7606e-04 - val_accuracy: 0.9576\n",
      "Epoch 8/50\n",
      "2360/2360 - 1s - loss: 5.4504e-04 - accuracy: 0.9775 - val_loss: 4.7567e-04 - val_accuracy: 0.9932\n",
      "Epoch 9/50\n",
      "2360/2360 - 1s - loss: 3.2890e-04 - accuracy: 0.9822 - val_loss: 3.4838e-04 - val_accuracy: 0.9932\n",
      "Epoch 10/50\n",
      "2360/2360 - 1s - loss: 3.4076e-04 - accuracy: 0.9890 - val_loss: 2.6594e-04 - val_accuracy: 0.9814\n",
      "Epoch 11/50\n",
      "2360/2360 - 1s - loss: 6.7219e-04 - accuracy: 0.9780 - val_loss: 5.1852e-04 - val_accuracy: 0.9542\n",
      "Epoch 12/50\n",
      "2360/2360 - 1s - loss: 5.0540e-04 - accuracy: 0.9771 - val_loss: 2.6843e-04 - val_accuracy: 0.9780\n",
      "738/1 - 0s - loss: 1.4696e-04 - accuracy: 0.9729\n",
      "[0.16983050847457626, 0.8301694915254237]\n",
      "Train on 2360 samples, validate on 590 samples\n",
      "Epoch 1/50\n",
      "2360/2360 - 2s - loss: 0.1023 - accuracy: 0.6076 - val_loss: 0.0809 - val_accuracy: 0.8576\n",
      "Epoch 2/50\n",
      "2360/2360 - 1s - loss: 0.0817 - accuracy: 0.7487 - val_loss: 0.0792 - val_accuracy: 0.8712\n",
      "Epoch 3/50\n",
      "2360/2360 - 1s - loss: 0.0737 - accuracy: 0.7758 - val_loss: 0.0724 - val_accuracy: 0.7915\n",
      "Epoch 4/50\n",
      "2360/2360 - 1s - loss: 0.0703 - accuracy: 0.7801 - val_loss: 0.0765 - val_accuracy: 0.8712\n",
      "Epoch 5/50\n",
      "2360/2360 - 1s - loss: 0.0671 - accuracy: 0.8110 - val_loss: 0.0670 - val_accuracy: 0.8220\n",
      "Epoch 6/50\n",
      "2360/2360 - 1s - loss: 0.0616 - accuracy: 0.8233 - val_loss: 0.0676 - val_accuracy: 0.8220\n",
      "Epoch 7/50\n",
      "2360/2360 - 1s - loss: 0.0563 - accuracy: 0.8364 - val_loss: 0.0688 - val_accuracy: 0.8576\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "738/1 - 0s - loss: 0.0591 - accuracy: 0.8442\n",
      "[0.04135593220338983, 0.9586440677966102]\n",
      "Train on 2360 samples, validate on 590 samples\n",
      "Epoch 1/50\n",
      "2360/2360 - 2s - loss: 0.0331 - accuracy: 0.5754 - val_loss: 0.0293 - val_accuracy: 0.2102\n",
      "Epoch 2/50\n",
      "2360/2360 - 1s - loss: 0.0266 - accuracy: 0.5695 - val_loss: 0.0277 - val_accuracy: 0.5898\n",
      "Epoch 3/50\n",
      "2360/2360 - 1s - loss: 0.0269 - accuracy: 0.6089 - val_loss: 0.0289 - val_accuracy: 0.7729\n",
      "Epoch 4/50\n",
      "2360/2360 - 1s - loss: 0.0242 - accuracy: 0.6826 - val_loss: 0.0280 - val_accuracy: 0.3339\n",
      "738/1 - 0s - loss: 0.0243 - accuracy: 0.3591\n",
      "[0.05322033898305085, 0.9467796610169491]\n",
      "Train on 2360 samples, validate on 590 samples\n",
      "Epoch 1/50\n",
      "2360/2360 - 2s - loss: 0.0353 - accuracy: 0.7288 - val_loss: 0.0169 - val_accuracy: 0.7271\n",
      "Epoch 2/50\n",
      "2360/2360 - 1s - loss: 0.0250 - accuracy: 0.7962 - val_loss: 0.0187 - val_accuracy: 0.6441\n",
      "Epoch 3/50\n",
      "2360/2360 - 1s - loss: 0.0180 - accuracy: 0.8182 - val_loss: 0.0107 - val_accuracy: 0.8729\n",
      "Epoch 4/50\n",
      "2360/2360 - 1s - loss: 0.0152 - accuracy: 0.8818 - val_loss: 0.0144 - val_accuracy: 0.7576\n",
      "Epoch 5/50\n",
      "2360/2360 - 1s - loss: 0.0132 - accuracy: 0.8924 - val_loss: 0.0139 - val_accuracy: 0.7644\n",
      "738/1 - 0s - loss: 0.0153 - accuracy: 0.7900\n",
      "[0.40779661016949154, 0.5922033898305085]\n",
      "Train on 2360 samples, validate on 590 samples\n",
      "Epoch 1/50\n",
      "2360/2360 - 2s - loss: 0.1818 - accuracy: 0.6386 - val_loss: 0.1375 - val_accuracy: 0.6729\n",
      "Epoch 2/50\n",
      "2360/2360 - 1s - loss: 0.1394 - accuracy: 0.7174 - val_loss: 0.1309 - val_accuracy: 0.6949\n",
      "Epoch 3/50\n",
      "2360/2360 - 1s - loss: 0.1201 - accuracy: 0.7678 - val_loss: 0.1267 - val_accuracy: 0.7153\n",
      "Epoch 4/50\n",
      "2360/2360 - 1s - loss: 0.1115 - accuracy: 0.7932 - val_loss: 0.1167 - val_accuracy: 0.7559\n",
      "Epoch 5/50\n",
      "2360/2360 - 1s - loss: 0.1034 - accuracy: 0.8051 - val_loss: 0.1140 - val_accuracy: 0.7610\n",
      "Epoch 6/50\n",
      "2360/2360 - 1s - loss: 0.0932 - accuracy: 0.8352 - val_loss: 0.1147 - val_accuracy: 0.7542\n",
      "Epoch 7/50\n",
      "2360/2360 - 1s - loss: 0.0840 - accuracy: 0.8487 - val_loss: 0.1204 - val_accuracy: 0.7915\n",
      "738/1 - 0s - loss: 0.0785 - accuracy: 0.7778\n",
      "[0.3227118644067797, 0.6772881355932203]\n",
      "Train on 2360 samples, validate on 590 samples\n",
      "Epoch 1/50\n",
      "2360/2360 - 2s - loss: 0.1600 - accuracy: 0.6288 - val_loss: 0.1131 - val_accuracy: 0.7814\n",
      "Epoch 2/50\n",
      "2360/2360 - 1s - loss: 0.1157 - accuracy: 0.7555 - val_loss: 0.1027 - val_accuracy: 0.7831\n",
      "Epoch 3/50\n",
      "2360/2360 - 1s - loss: 0.1043 - accuracy: 0.7852 - val_loss: 0.0937 - val_accuracy: 0.8186\n",
      "Epoch 4/50\n",
      "2360/2360 - 1s - loss: 0.0901 - accuracy: 0.8191 - val_loss: 0.0874 - val_accuracy: 0.8271\n",
      "Epoch 5/50\n",
      "2360/2360 - 1s - loss: 0.0814 - accuracy: 0.8390 - val_loss: 0.0832 - val_accuracy: 0.8085\n",
      "Epoch 6/50\n",
      "2360/2360 - 1s - loss: 0.0739 - accuracy: 0.8551 - val_loss: 0.0798 - val_accuracy: 0.8169\n",
      "Epoch 7/50\n",
      "2360/2360 - 1s - loss: 0.0673 - accuracy: 0.8686 - val_loss: 0.0786 - val_accuracy: 0.8220\n",
      "Epoch 8/50\n",
      "2360/2360 - 1s - loss: 0.0596 - accuracy: 0.8852 - val_loss: 0.0801 - val_accuracy: 0.8203\n",
      "Epoch 9/50\n",
      "2360/2360 - 1s - loss: 0.0552 - accuracy: 0.8983 - val_loss: 0.0795 - val_accuracy: 0.8661\n",
      "738/1 - 0s - loss: 0.0430 - accuracy: 0.8564\n",
      "[['0.51/0.43/0.67'], ['0.42/0.35/0.59'], ['0.78/0.67/0.92'], ['0.48/0.34/0.85'], ['0.66/0.63/0.70'], ['0.73/0.67/0.86'], ['0.19/0.11/1.00'], ['0.61/0.53/0.73'], ['0.26/0.26/0.61'], ['0.49/0.39/0.81'], ['0.73/0.81/0.68'], ['0.77/0.73/0.82'], ['0.55/0.49/0.77']]\n"
     ]
    }
   ],
   "source": [
    "result = []\n",
    "run_num = 10\n",
    "max_length = 200\n",
    "embedding_dim = 100\n",
    "weight = 0.2\n",
    "(x_train, y_train), (x_test, y_test),word_index = prepare_train(max_length)\n",
    "embedding_matrix = get_embedding_matrix(get_model(model_type='word2vec', model_name='word2vec'))\n",
    "#  选择使用word2vec或doc2vec\n",
    "for i in range(run_num):\n",
    "    (models, histories) = run_model(x_train,y_train,\n",
    "                                    x_test,y_test, \n",
    "                                    word_index=word_index,\n",
    "                                    embedding_dim=embedding_dim,\n",
    "                                    max_length=max_length, \n",
    "                                    embedding_matrix=embedding_matrix,\n",
    "                                    weight = weight,\n",
    "                                    model_name='TextCNN_model') #  选择使用的模型\n",
    "    result.append(get_score(models=models,x_test=x_test,y_test=y_test))\n",
    "save_result(result=result,file_name='TextCNN_word2vec_embed100_len200_10run',run_num=run_num) #  保存得分到指定文件"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "训练分类器，每个类别训练10个分类器用于计算平均值，总共训练120次<br>\n",
    "根据对应参数选择训练方法：<br>\n",
    "\n",
    "run_num = 10 -> 训练多少轮求均值<br>\n",
    "max_length = 200 -> 文本定长<br>\n",
    "embedding_dim = 100 -> embedding_dim 词向量维数<br>\n",
    "weight = 0.2 -> 损失函数权重<br>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
